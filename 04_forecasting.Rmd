---
title: "04_forecasting"
---
---
title: "Forecasting"
---

```{r, include=FALSE, echo=FALSE}
#install.packages(c("readr", "data.table", "psych","dplyr", "tidyr", "reshape2", "lubridate", "forecast", "astsa", "zoo", "nowcasting", "TSstudio", "ggplot2", "pastecs","readxl", "grid", "gridExtra", "kableExtra","knitr", "fpp2", "tstools", "tseries", "plotly", "scales","midasr"))
library(readr)
library(data.table)
library(psych)
library(dplyr)
library(tidyr)
library(reshape2)
library(lubridate)
library(forecast)
library(astsa)
library(zoo)
library(nowcasting)
library(TSstudio)
library(ggplot2)
library(pastecs)
library(readxl)
library(gridExtra)
library(grid)
library(kableExtra)
library(knitr)
library(fpp2)
library(tstools)
library(tseries)
library(plotly)
library(scales)
library(midasr)
library(tsfknn)
```

```{r setup, include=FALSE, echo=FALSE}
require("knitr")
opts_knit$set(root.dir = "~/Documents/GitHub/RIDB/data")
```

#Forecasting

Get five campgrounds based on RIDB # of Sites
Blackwoods and Flamingo were on top of the list manifested odd occupancy, hence dropped

MATHER CAMPGROUND	Grand Canyon	328	307	Open Year Round	2	365
MORAINE PARK CAMPGROUND	Rocky Mountain	247	236	Open Year Round	4	365
UPPER PINES	Yosemite	238	235	Open Year Round	1	365
BIG MEADOWS	Shenandoah	221	221	Open March 30 - November 12	4	365
ELKMONT CAMPGROUND	Great Smoky Mountains	220	211	Open 3/9 - 11/25	4	365

```{r format campground data for forecasting}
rm(list=ls())

#load functions
source("~/Documents/GitHub/RIDB/formatCamp.R")
source("~/Documents/GitHub/RIDB/unitTest.R")
source("~/Documents/GitHub/RIDB/campMGraph.R")

#load data
data <- fread("~/Documents/GitHub/RIDB/data/final_data.csv")

#unique(data$id[data$Campground=="MATHER CAMPGROUND"]) #65
formatCamp(65)
matherD <- fread("descriptive_65.csv")
mather <- fread("campground_65.csv")
matherM <- fread("campground_monthly_65.csv")

#unique(data$id[data$Campground=="MORAINE PARK CAMPGROUND"]) #67
formatCamp(67)
moraineD <- fread("descriptive_67.csv")
moraine <- fread("campground_67.csv")
moraineM <- fread("campground_monthly_67.csv")

#unique(data$id[data$Campground=="UPPER PINES"]) #106
formatCamp(106)
upperD <- fread("descriptive_106.csv")
upper <- fread("campground_106.csv")
upperM <- fread("campground_monthly_106.csv")

#unique(data$id[data$Campground=="BIG MEADOWS"]) #7
formatCamp(7)
meadowsD <- fread("descriptive_7.csv")
meadows <- fread("campground_7.csv")
meadowsM <- fread("campground_monthly_7.csv")

#unique(data$id[data$Campground=="ELKMONT CAMPGROUND"]) #42
formatCamp(42)
elkmontD <- fread("descriptive_42.csv")
elkmont <- fread("campground_42.csv")
elkmontM <- fread("campground_monthly_42.csv")

#unique(data$id[data$Campground=="BLACKWOODS CAMPGROUND"]) #11
#formatCamp(11)
#black <- fread("campground_monthly_11.csv") #weird occupancy

#unique(data$id[data$Campground=="FLAMINGO"]) #45
#formatCamp(45)
#flamingo <- fread("campground_monthly_45.csv") #weird occupancy

#for consistency, start all camp data from 2007 May
elkmontM <- elkmontM[which(elkmontM$month>"2007-04-01")]
matherM <- matherM[which(matherM$month>"2007-04-01")]
meadowsM <- meadowsM[which(meadowsM$month>"2007-04-01")]
moraineM <- moraineM[which(moraineM$month>"2007-04-01")]
upperM <- upperM[which(upperM$month>"2007-04-01")]
```

```{r summary tables}
summary(meadowsD)
summary(elkmontD)
summary(matherD)
summary(moraineD)
summary(upperD)

#occupancy greater than 100%
dplyr::count(meadowsD[meadowsD$occupancy>1])/dplyr::count(meadowsD)
dplyr::count(elkmontD[elkmontD$occupancy>1])/dplyr::count(elkmontD)
dplyr::count(matherD[matherD$occupancy>1])/dplyr::count(matherD)
dplyr::count(moraineD[moraineD$occupancy>1])/dplyr::count(moraineD)
dplyr::count(upperD[upperD$occupancy>1])/dplyr::count(upperD)

#maximum occupancy
max(meadowsD$occupancy)
max(elkmontD$occupancy)
max(matherD$occupancy)
max(moraineD$occupancy)
max(upperD$occupancy)

rm(meadowsD, elkmontD, matherD, moraineD, upperD)
```


```{r occupancy graphs}
p1 <- campMGraph(mather, matherM)+ggtitle("Mather, Grand Canyon")
p2 <- campMGraph(elkmont, elkmontM)+ggtitle("Elkmont, Great Smoky Mountains")
p3 <- campMGraph(meadows, meadowsM)+ggtitle("Big Meadows, Shenandoah")
p4 <- campMGraph(moraine, moraineM)+ggtitle("Moraine, Rocky Mountain")
p5 <- campMGraph(upper, upperM)+ggtitle("Upper Pines, Yosemite")

pdf("occupancy.pdf", 16, 9)
grid.arrange(p1, p2, p3, p4, p5, ncol=3, nrow=2)
dev.off()
```

```{r Unit root tests}
## Unit root test
#install.packages(c("fUnitRoots", "uroot"))
library(fUnitRoots)
library(uroot)
library(urca)

unitTest(meadowsM)
unitTest(elkmontM)
unitTest(matherM)
unitTest(moraineM)
unitTest(upperM)
```

## Moving Average
```{r Moving Average}
source("~/GitHub/RIDB/maProcess.R")
#maProcess(elkmontM, 12)
maProcess(elkmontM, 6)
maProcess(matherM, 6)
maProcess(meadowsM, 6)
maProcess(moraineM, 6)
maProcess(upperM, 6)
```

## ARIMA
```{r ARIMA}
source("~/GitHub/RIDB/arimaProcess.R")
#arimaProcess(dataname, number of forecasts)

arimaProcess(elkmontM, 6)
arimaProcess(matherM, 6)
arimaProcess(meadowsM, 6)
arimaProcess(moraineM, 6)
arimaProcess(upperM, 6)
```

Our data is inevitably seasonal. Hence, we will run seasonal ARIMA model. Refer to https://onlinecourses.science.psu.edu/stat510/node/67/ for more information.
We will test time-series analysis with one ID. We will run each ID separately as each facility has different length of time.

Some useful sources for forecasting with R:
http://a-little-book-of-r-for-time-series.readthedocs.io/en/latest/src/timeseries.html

https://robjhyndman.com/hyndsight/dailydata/

## SARIMA
```{r SARIMA}
source("~/GitHub/RIDB/sarimaProcess.R")
sarimaProcess(elkmontM, 3)
sarimaProcess(matherM, 3)
sarimaProcess(meadowsM, 3)
sarimaProcess(moraineM, 3)
sarimaProcess(upperM, 3)

sarimaProcess(meadowsM, 6)
sarimaProcess(elkmontM, 6)
sarimaProcess(matherM, 6)
sarimaProcess(moraineM, 6)
sarimaProcess(upperM, 6)
```

## ETS
```{r ETS}
source("~/Documents/GitHub/RIDB/etsProcess.R")
etsProcess(elkmontM, 6)
etsProcess(matherM, 6)
etsProcess(meadowsM, 6)
etsProcess(moraineM, 6)
etsProcess(upperM, 6)
```

##NNAR
```{r NNAR}
source("~/Documents/GitHub/RIDB/nnarProcess.R")
nnarProcess(elkmontM, 3)
nnarProcess(matherM, 3)
nnarProcess(meadowsM, 3)
nnarProcess(moraineM, 3)
nnarProcess(upperM, 3)

nnarProcess(elkmontM, 6)
nnarProcess(matherM, 6)
nnarProcess(meadowsM, 6)
nnarProcess(moraineM, 6)
nnarProcess(upperM, 6)

nnarProcess(elkmontM, 12)
nnarProcess(matherM, 12)
nnarProcess(meadowsM, 12)
nnarProcess(moraineM, 12)
nnarProcess(upperM, 12)
```

## ETS + SARIMA + NNAR
```{r Combination}
source("~/GitHub/RIDB/combProcess.R")
combProcess(elkmontM, 3)
combProcess(matherM, 3)
combProcess(meadowsM, 3)
combProcess(moraineM, 3)
combProcess(upperM, 3)

combProcess(elkmontM, 6)
combProcess(matherM, 6)
combProcess(meadowsM, 6)
combProcess(moraineM, 6)
combProcess(upperM, 6)

combProcess(elkmontM, 12)
combProcess(matherM, 12)
combProcess(meadowsM, 12)
combProcess(moraineM, 12)
combProcess(upperM, 12)
```

```{r 12 months graph}
source("~/Documents/GitHub/RIDB/combProcess2.R")
b<-combProcess2(elkmontM, 12)
c<-combProcess2(matherM, 12)
a<-combProcess2(meadowsM, 12)
d<-combProcess2(moraineM, 12)
e<-combProcess2(upperM, 12)

cbbPalette <- c("#D55E00", "#000000", "#0072B2")

a<-ggplot(data = a, aes(x=Time, y=value, color=series)) +
    labs(y="Occupancy (%)", title="Big Meadows, Shenandoah National Park")  +
    geom_line(aes(y=gtemp , col='Real'), size=1.2, alpha=.9)  +
    geom_line(aes(y=gtempl, col='Combination'), size=1.2, alpha=.5)    +
    geom_line(aes(y=gtempa, col='SARIMA'), size=1.2, alpha=.5)    +
    theme(panel.background = element_blank()) + 
    scale_y_continuous(breaks=seq(0,100,25)) +
    scale_x_date(date_breaks = "2 month", date_labels = "%b %Y") +
    scale_colour_manual(values=cbbPalette)

b<-ggplot(data = b, aes(x=Time, y=value, color=series )  )  +
    labs(y="Occupancy (%)", title="Elkmont, Great Smoky Mountains National Park")       +
    geom_line(aes(y=gtemp , col='Real'), size=1.2, alpha=.9)  +
    geom_line(aes(y=gtempl, col='Combination'), size=1.2, alpha=.5)    +
    geom_line(aes(y=gtempa, col='SARIMA'), size=1.2, alpha=.5)    +
    theme(panel.background = element_blank()) + 
    scale_y_continuous(breaks=seq(0,100,25)) +
    scale_x_date(date_breaks = "2 month", date_labels = "%b %Y") +
    scale_colour_manual(values=cbbPalette)

c<-ggplot(data = c, aes(x=Time, y=value, color=series )  ) +
    labs(y="Occupancy (%)", title="Mather, Grand Canyon National Park")    +
    geom_line(aes(y=gtemp , col='Real'), size=1.2, alpha=.9)  +
    geom_line(aes(y=gtempl, col='Combination'), size=1.2, alpha=.5)    +
    geom_line(aes(y=gtempa, col='SARIMA'), size=1.2, alpha=.5)    +
    theme(panel.background = element_blank()) + 
    scale_y_continuous(breaks=seq(0,100,25)) +
    scale_x_date(date_breaks = "2 month", date_labels = "%b %Y") +
    scale_colour_manual(values=cbbPalette)

d<-ggplot(data = d, aes(x=Time, y=value, color=series )  ) +
    labs(y="Occupancy (%)", title="Moraine, Rocky Mountain National Park")    +
    geom_line(aes(y=gtemp , col='Real'), size=1.2, alpha=.9)  +
    geom_line(aes(y=gtempl, col='Combination'), size=1.2, alpha=.5)    +
    geom_line(aes(y=gtempa, col='SARIMA'), size=1.2, alpha=.5)    +
    theme(panel.background = element_blank()) + 
    scale_y_continuous(breaks=seq(0,100,25)) +
    scale_x_date(date_breaks = "2 month", date_labels = "%b %Y") +
    scale_colour_manual(values=cbbPalette)

e<-ggplot(data = e, aes(x=Time, y=value, color=series )  )  +
    labs(y="Occupancy (%)", title="Upper Pines, Yosemite National Park")   +
    geom_line(aes(y=gtemp , col='Real'), size=1.2, alpha=.9)  +
    geom_line(aes(y=gtempl, col='Combination'), size=1.2, alpha=.5)    +
    geom_line(aes(y=gtempa, col='SARIMA'), size=1.2, alpha=.5)    +
    theme(panel.background = element_blank()) + 
    scale_y_continuous(breaks=seq(0,100,25)) +
    scale_x_date(date_breaks = "2 month", date_labels = "%b %Y") +
    scale_colour_manual(values=cbbPalette)

source("~/Documents/Github/RIDB/grid_arrange_shared_legend.R")
pdf("forecasting12.pdf", 16, 9)
grid_arrange_shared_legend(a, b, c, d, e, ncol=3, nrow=2)
dev.off()  
```

```{r 6 months graph}
source("~/Documents/GitHub/RIDB/combProcess2.R")
b<-combProcess2(elkmontM, 6)
c<-combProcess2(matherM, 6)
a<-combProcess2(meadowsM, 6)
d<-combProcess2(moraineM, 6)
e<-combProcess2(upperM, 6)

cbbPalette <- c("#D55E00", "#000000", "#0072B2")

a<-ggplot(data = a, aes(x=Time, y=value, color=series)) +
    labs(y="Occupancy (%)", title="Big Meadows, Shenandoah National Park")  +
    geom_line(aes(y=gtemp , col='Real'), size=1.2, alpha=.9)  +
    geom_line(aes(y=gtempl, col='Combination'), size=1.2, alpha=.5)    +
    geom_line(aes(y=gtempa, col='SARIMA'), size=1.2, alpha=.5)    +
    theme(panel.background = element_blank()) + 
    scale_y_continuous(breaks=seq(0,100,25)) +
    scale_x_date(date_breaks = "2 month", date_labels = "%b %Y") +
    scale_colour_manual(values=cbbPalette)

b<-ggplot(data = b, aes(x=Time, y=value, color=series )  )  +
    labs(y="Occupancy (%)", title="Elkmont, Great Smoky Mountains National Park")       +
    geom_line(aes(y=gtemp , col='Real'), size=1.2, alpha=.9)  +
    geom_line(aes(y=gtempl, col='Combination'), size=1.2, alpha=.5)    +
    geom_line(aes(y=gtempa, col='SARIMA'), size=1.2, alpha=.5)    +
    theme(panel.background = element_blank()) + 
    scale_y_continuous(breaks=seq(0,100,25)) +
    scale_x_date(date_breaks = "2 month", date_labels = "%b %Y") +
    scale_colour_manual(values=cbbPalette)

c<-ggplot(data = c, aes(x=Time, y=value, color=series )  ) +
    labs(y="Occupancy (%)", title="Mather, Grand Canyon National Park")    +
    geom_line(aes(y=gtemp , col='Real'), size=1.2, alpha=.9)  +
    geom_line(aes(y=gtempl, col='Combination'), size=1.2, alpha=.5)    +
    geom_line(aes(y=gtempa, col='SARIMA'), size=1.2, alpha=.5)    +
    theme(panel.background = element_blank()) + 
    scale_y_continuous(breaks=seq(0,100,25)) +
    scale_x_date(date_breaks = "2 month", date_labels = "%b %Y") +
    scale_colour_manual(values=cbbPalette)

d<-ggplot(data = d, aes(x=Time, y=value, color=series )  ) +
    labs(y="Occupancy (%)", title="Moraine, Rocky Mountain National Park")    +
    geom_line(aes(y=gtemp , col='Real'), size=1.2, alpha=.9)  +
    geom_line(aes(y=gtempl, col='Combination'), size=1.2, alpha=.5)    +
    geom_line(aes(y=gtempa, col='SARIMA'), size=1.2, alpha=.5)    +
    theme(panel.background = element_blank()) + 
    scale_y_continuous(breaks=seq(0,100,25)) +
    scale_x_date(date_breaks = "2 month", date_labels = "%b %Y") +
    scale_colour_manual(values=cbbPalette)

e<-ggplot(data = e, aes(x=Time, y=value, color=series )  )  +
    labs(y="Occupancy (%)", title="Upper Pines, Yosemite National Park")   +
    geom_line(aes(y=gtemp , col='Real'), size=1.2, alpha=.9)  +
    geom_line(aes(y=gtempl, col='Combination'), size=1.2, alpha=.5)    +
    geom_line(aes(y=gtempa, col='SARIMA'), size=1.2, alpha=.5)    +
    theme(panel.background = element_blank()) + 
    scale_y_continuous(breaks=seq(0,100,25)) +
    scale_x_date(date_breaks = "2 month", date_labels = "%b %Y") +
    scale_colour_manual(values=cbbPalette)

source("~/Documents/Github/RIDB/grid_arrange_shared_legend.R")
pdf("forecasting6.pdf", 16, 9)
grid_arrange_shared_legend(a, b, c, d, e, ncol=3, nrow=2)
dev.off()  
```

## ENSEMBLE
```{r, echo=FALSE}

  
```

##KNN
```{r KNN}
source("~/Documents/GitHub/RIDB/knnProcess.R")

knnProcess(elkmontM, 6)
knnProcess(matherM, 6)
knnProcess(meadowsM, 6)
knnProcess(moraineM, 6)
knnProcess(upperM, 6)
```

##MAPE

```{r}
source("~/GitHub/RIDB/mapeProcess.R")
mapeProcess(elkmontM, 2)
mapeProcess(matherM, 2)
mapeProcess(meadowsM, 2)
mapeProcess(moraineM, 2)
mapeProcess(upperM, 2)

mapeProcess(elkmontM, 3)
mapeProcess(matherM, 3)
mapeProcess(meadowsM, 3)
mapeProcess(moraineM, 3)
mapeProcess(upperM, 3)

mapeProcess(elkmontM, 6)
mapeProcess(matherM, 6)
mapeProcess(meadowsM, 6)
mapeProcess(moraineM, 6)
mapeProcess(upperM, 6)

mapeProcess(elkmontM, 12)
mapeProcess(matherM, 12)
mapeProcess(meadowsM, 12)
mapeProcess(moraineM, 12)
mapeProcess(upperM, 12)

```







```{r, include=FALSE, echo=FALSE}
#install.packages(c("rpart", "party", "randomForest"))
library(rpart) # decision tree method
library(party) # decision tree method
library(randomForest) # ensemble learning method
```

```{r ensemble}
n_date <- unique(matherM[, month]) #128
period <- 12
m <- length(n_date) - 12

#I will use 118 months of data for training regression trees methods. Forecasts will be performed to one, three, six, and twelve months ahead. Let's extract train and test set from the dataset.
data_train <- matherM[month %in% n_date[1:m]]
data_train$month <- as.Date(data_train$month)

data_test_1 <- matherM[month %in% n_date[119]]
data_test_3 <- matherM[month %in% n_date[119:120]]
data_test_6 <- matherM[month %in% n_date[119:123]]
data_test_12 <- matherM[month %in% n_date[119:130]]
```

#Bagging

Bagging or bootstrap aggregating, is ensemble learning meta-algorithm used to improve prediction accuracy and to overcome (avoid) overfitting. The algorithm is very simple. The first step is sampling a training dataset with replacement with some defined sample ratio (e.g. 0.7). Then a model is trained on a new train set. This procedure is repeated N_boot times (e.g. 100). Final ensemble prediction is just average of N_boot predictions. For aggregating predictions, the median can be also used and will be used in this post.

##Bagging + RPART

The first "bagged method is RPART (CART) tree. Campsite reservation is firstly detrended by STL decomposition and trend part is forecasted (modeled) by ARIMA (auto.arima function). Seasonal and remainder part is then forecasted by regression tree model. More detailed description and explanations are in my previous post about regression trees methods. Let's define train and test data (by matrix_train and matrix_test).

```{r bagging}
data_ts <- ts(data_train$occupancy, freq = 12, start = c(2007, 5))
decomp_ts <- stl(data_ts, s.window = "periodic", robust = TRUE)$time.series
 
trend_part <- ts(decomp_ts[,2])
 
trend_fit <- auto.arima(trend_part) # ARIMA
trend_for <- as.vector(forecast(trend_fit, period)$mean) # trend forecast
 
data_msts <- msts(data_train$occupancy, seasonal.periods = c(period, period*12))
 
K <- 2
fuur <- fourier(data_msts, K = c(K, K)) # Fourier features to model (monthly and yearly)
 
N <- nrow(data_train)
window <- (N / period) - 1
 
new_load <- rowSums(decomp_ts[, c(1,3)]) # detrended original time series
lag_seas <- decomp_ts[1:(period*window), 1] # lag feature to model
 
matrix_train <- data.table(Load = tail(new_load, window*period),
                           fuur[(period + 1):N,],
                           Lag = lag_seas)
 
# create testing data matrix
test_lag <- decomp_ts[((period*window)+1):N, 1]
fuur_test <- fourier(data_msts, K = c(K, K), h = period)
 
matrix_test <- data.table(fuur_test,
                          Lag = test_lag)
```

I will perform 100 bootstrapped forecasts by RPART, that will be stored in the matrix of size 
100?48(pred_mat). Additional four parameters will be also sampled (randomized) to avoid overfitting. Sample ratio for sampling train set is sampled in the range from 0.7 to 0.9. Three hyperparameters of RPART are sampled also: minsplit, maxdepth and complexity parameter cp. Hyperparameters are sampled around values set on my previous post modeling.

```{r}
N_boot <- 100 # number of bootstraps
 
pred_mat <- matrix(0, nrow = N_boot, ncol = period)
for(i in 1:N_boot) {
  
  matrixSam <- matrix_train[sample(1:(N-period),
                                   floor((N-period) * sample(seq(0.7, 0.9, by = 0.01), 1)),
                                   replace = TRUE)] # sampling with sampled ratio from 0.7 to 0.9
  tree_bag <- rpart(Load ~ ., data = matrixSam,
                    control = rpart.control(minsplit = sample(2:3, 1),
                                            maxdepth = sample(26:30, 1),
                                            cp = sample(seq(0.0000009, 0.00001, by = 0.0000001), 1)))
  
  # new data and prediction
  pred_mat[i,] <- predict(tree_bag, matrix_test) + mean(trend_for)
}
```

Let's compute median of forecasts and visualize all created forecasts. For ggplot visualization needs we must use melt function to the matrix of forecasts pred_mat.

```{r}
pred_melt_rpart <- data.table(melt(pred_mat))
 
pred_ave_rpart <- pred_melt_rpart[, .(value = median(value)), by = .(Var2)]
pred_ave_rpart[, Var1 := "RPART_Bagg"]
 
ggplot(pred_melt_rpart, aes(Var2, value, group = Var1)) +
  geom_line(alpha = 0.75) +
  geom_line(data = pred_ave_rpart, aes(Var2, value), color = "firebrick2", alpha = 0.9, size = 2) +
  labs(x = "Time", y = "Occupnacy (%)", title = "Bagging with RPART") + 
    theme(axis.title.y = element_text(size = 9)) + 
    theme(axis.title.x = element_text(size = 9))  +
    theme(panel.background = element_blank())   + 
    scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12),labels=as.character(c("Sep 2016", "Oct 2016", "Nov 2016", "Dec 2016", "Jan 2017", "Feb 2017" ,"Mar 2017","Apr 2017","May 2017","Jun 2017","Jul 2017","Aug 2017"))) +
    scale_y_continuous(breaks=seq(0,100,25))
```

The red line is median of forecasts. We can see that created forecasts by RPART have typical rectangular shape, but final ensemble forecasts has nice smooth behaviour. 

##Bagging with CTREE
The second "bagged" regression tree method is CTREE. I will randomize only mincriterion hyperparameter of CTREE method that decisions about splitting a node. The sample ratio is of course sampled (randomized) as well as in the previous case with RPART.

```{r}
pred_mat <- matrix(0, nrow = N_boot, ncol = period)
for(i in 1:N_boot) {
  
  matrixSam <- matrix_train[sample(1:(N-period),
                                   floor((N-period) * sample(seq(0.7, 0.9, by = 0.01), 1)),
                                   replace = TRUE)] # sampling with sampled ratio from 0.7 to 0.9
  tree_bag <- party::ctree(Load ~ ., data = matrixSam,
                           controls = party::ctree_control(teststat = c("quad"),
                                                           testtype = c("Teststatistic"),
                                                           mincriterion = sample(seq(0.88, 0.97, by = 0.005), 1),
                                                           minsplit = 1,
                                                           minbucket = 1,
                                                           mtry = 0, maxdepth = 0))
  
  # new data and prediction
  pred_mat[i,] <- predict(tree_bag, matrix_test) + mean(trend_for)
}

pred_melt_ctree <- data.table(melt(pred_mat))
 
pred_ave_ctree <- pred_melt_ctree[, .(value = median(value)), by = .(Var2)]
pred_ave_ctree[, Var1 := "CTREE_Bagg"]
 
ggplot(pred_melt_ctree, aes(Var2, value, group = Var1)) +
  geom_line(alpha = 0.75) +
  geom_line(data = pred_ave_ctree, aes(Var2, value), color = "firebrick2", alpha = 0.9, size = 2) +
  labs(x = "Time", y = "Load (kW)", title = "Bagging with CTREE")


rf_model <- randomForest(Load ~ ., data = data.frame(matrix_train),
                         ntree = 1000, mtry = 3, nodesize = 5, importance = TRUE)

pred_rf <- predict(rf_model, data.frame(matrix_test)) + mean(trend_for)

pred_rf <- data.table(value = pred_rf, Var2 = 1:12, Var1 = "RF")
 
pred_true <- data.table(value = data_test_12$occupancy, Var2 = 1:12, Var1 = "Real")

pred_avg <- cbind(pred_ave_rpart[,2], pred_ave_ctree[,2], pred_rf[,1])
pred_avg <- transform(pred_avg, average_value = rowMeans(pred_avg, na.rm = TRUE))
pred_avg[,1:3] <-NULL
colnames(pred_avg) <- c("value")
pred_avg <- data.table(value = pred_avg$value, Var2 = 1:12, Var1 = "Average")

preds_all <- rbindlist(list(pred_ave_rpart, pred_ave_ctree, pred_rf, pred_avg, pred_true), use.names = T)
 
ggplot(preds_all, aes(Var2, value, color = as.factor(Var1))) +
  geom_line(alpha = 0.7, size = 1.2) +
  labs(x = "Time", y = "Load (kW)", title = "Comparison of Ensemble Learning forecasts") +
  guides(color=guide_legend(title="Method")) 
```